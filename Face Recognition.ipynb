{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Processing\n",
    "These sections are utilized to take photos from my webcam, rename, and place photos from LFW dataset into proper folders, as well as split the dataset into training and testing partitions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "def rename_images(directory):\n",
    "    # Dictionaries to store counts\n",
    "    image_count = {}\n",
    "    name_counter = {}\n",
    "    total_names = 0\n",
    "    \n",
    "    # Iterate through the files in the directory\n",
    "    for filename in os.listdir(directory):\n",
    "        if filename.lower().endswith(('.png', '.jpg', '.jpeg', '.gif')):\n",
    "            # Split filename and extension\n",
    "            name, ext = os.path.splitext(filename)\n",
    "            name,x,y=name.split('.')\n",
    "            #print(name)\n",
    "            \n",
    "            # Get the count for the filename or initialize to 0\n",
    "            count = image_count.get(name, 0)\n",
    "            \n",
    "            # Increment the name counter or add new name\n",
    "            if name not in name_counter:\n",
    "                total_names += 1\n",
    "                name_counter[name] = total_names\n",
    "                os.makedirs(os.path.join(directory,name))\n",
    "            \n",
    "            # New filename with counts\n",
    "            new_filename = f\"{name}.{name_counter[name]-1}.{count}{ext}\"\n",
    "            new_path = os.path.join(directory, name, new_filename)\n",
    "            \n",
    "            # Rename the file\n",
    "            os.replace(os.path.join(directory, filename), new_path)\n",
    "            #print(new_path)\n",
    "            \n",
    "            # Update counts for the filename\n",
    "            image_count[name] = count + 1\n",
    "\n",
    "# Replace 'directory_path' with the path of your directory containing images\n",
    "directory_path = 'dataset'\n",
    "rename_images(directory_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import uuid\n",
    "\n",
    "ETHAN_PATH = os.path.join('data', 'ethan')\n",
    "SADIE_PATH = os.path.join('data', 'sadie')\n",
    "MATT_PATH = os.path.join('data', 'matt')\n",
    "\n",
    "\"\"\"\n",
    "os.makedirs(ETHAN_PATH)\n",
    "os.makedirs(SADIE_PATH)\n",
    "os.makedirs(MATT_PATH)\n",
    "\"\"\"\n",
    "\n",
    "cap = cv2.VideoCapture(0)\n",
    "while cap.isOpened(): \n",
    "    ret, frame = cap.read()\n",
    "   \n",
    "    # Cut down frame to 250x250px\n",
    "    frame = frame[120:120+250,200:200+250, :]\n",
    "    \n",
    "    # Collect anchors \n",
    "    if cv2.waitKey(1) & 0XFF == ord('e'):\n",
    "        # Create the unique file path \n",
    "        imgname = os.path.join(ETHAN_PATH, '{}.jpg'.format(uuid.uuid1()))\n",
    "        # Write out anchor image\n",
    "        cv2.imwrite(imgname, frame)\n",
    "    \n",
    "    # Collect positives\n",
    "    if cv2.waitKey(1) & 0XFF == ord('s'):\n",
    "        # Create the unique file path \n",
    "        imgname = os.path.join(SADIE_PATH, '{}.jpg'.format(uuid.uuid1()))\n",
    "        # Write out positive image\n",
    "        cv2.imwrite(imgname, frame)\n",
    "\n",
    "    # Collect positives\n",
    "    if cv2.waitKey(1) & 0XFF == ord('m'):\n",
    "        # Create the unique file path \n",
    "        imgname = os.path.join(MATT_PATH, '{}.jpg'.format(uuid.uuid1()))\n",
    "        # Write out positive image\n",
    "        cv2.imwrite(imgname, frame)\n",
    "    \n",
    "    # Show image back to screen\n",
    "    cv2.imshow('Image Collection', frame)\n",
    "    \n",
    "    # Breaking gracefully\n",
    "    if cv2.waitKey(1) & 0XFF == ord('q'):\n",
    "        break\n",
    "        \n",
    "# Release the webcam\n",
    "cap.release()\n",
    "# Close the image show frame\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import splitfolders\n",
    "\n",
    "inputFolder='data'\n",
    "outputFolder='testDataset2'\n",
    "splitfolders.ratio(inputFolder, output=outputFolder, seed=42, ratio=(.8,.2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Facial Recognition\n",
    "This section is where the data is imported, the model is trained, and the model is tested. It requires two folders, one for training and one for testing, to be in the same directory and have subfolders containing the different classes of items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True Positive: 20\n",
      "True Negative: 55\n",
      "False Positive: 105\n",
      "False Negative: 0\n",
      "Accuracy: 0.4167\n",
      "Error Rate: 0.5833\n",
      "Precision: 0.1600\n",
      "False Discovery Rate: 0.8400\n",
      "True Positive Rate: 0.1111\n",
      "False Negative Rate: 0.0000\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "# Load the pre-trained Haar cascade for face detection\n",
    "face_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml')\n",
    "\n",
    "# Initialize an LBPH face recognizer\n",
    "recognizer = cv2.face.LBPHFaceRecognizer_create()\n",
    "\n",
    "# Function to load images and labels from a directory\n",
    "def load_images_from_folder(folder):\n",
    "    images = []\n",
    "    labels = []\n",
    "    label = 0\n",
    "    for subfolder in os.listdir(folder):\n",
    "        subfolder_path = os.path.join(folder, subfolder)\n",
    "        if os.path.isdir(subfolder_path):\n",
    "            for filename in os.listdir(subfolder_path):\n",
    "                if filename.endswith('.jpg'):\n",
    "                    img = cv2.imread(os.path.join(subfolder_path, filename))\n",
    "                    if img is not None:\n",
    "                        images.append(cv2.cvtColor(img, cv2.COLOR_BGR2GRAY))\n",
    "                        labels.append(label)\n",
    "            label += 1\n",
    "    return images, labels\n",
    "\n",
    "# Function to train the recognizer with training images\n",
    "def train_recognizer(train_images_folder):\n",
    "    images, labels = load_images_from_folder(train_images_folder)\n",
    "    recognizer.train(images, np.array(labels))\n",
    "\n",
    "# Function to update recognizer with additional training images\n",
    "def update_recognizer(train_images_folder):\n",
    "    images, labels = load_images_from_folder(train_images_folder)\n",
    "    recognizer.update(images, np.array(labels))  # Update the model with new data\n",
    "\n",
    "# Function to calculate recognition metrics\n",
    "def calculate_metrics(test_images_folder):\n",
    "    test_images, test_labels = load_images_from_folder(test_images_folder)\n",
    "\n",
    "    true_positive = 0\n",
    "    false_positive = 0\n",
    "    true_negative = 0\n",
    "    false_negative = 0\n",
    "\n",
    "    for idx, img in enumerate(test_images):\n",
    "        faces_found = face_cascade.detectMultiScale(img, scaleFactor=1.3, minNeighbors=5)\n",
    "\n",
    "        for (x, y, w, h) in faces_found:\n",
    "            label, _ = recognizer.predict(img[y:y+h, x:x+w])\n",
    "\n",
    "            # True positive: correctly recognized faces with matching labels\n",
    "            if label == test_labels[idx]:\n",
    "                true_positive += 1\n",
    "            # False positive: incorrectly recognized faces with non-matching labels\n",
    "            else:\n",
    "                false_positive += 1\n",
    "\n",
    "    total_faces = len(test_images)\n",
    "    true_negative = total_faces - (true_positive + false_positive)\n",
    "    false_negative = 0  # No false negatives in this setup (assumes all faces are present in the test set)\n",
    "\n",
    "    # Calculate error rate, precision, false discovery rate, true positive rate, false negative rate, accuracy\n",
    "    error_rate = (false_positive + false_negative) / total_faces if total_faces > 0 else -1\n",
    "    precision = true_positive / (true_positive + false_positive) if (true_positive + false_positive) > 0 else -1\n",
    "    false_discovery_rate = false_positive / (false_positive + true_positive) if (false_positive + true_positive) > 0 else -1\n",
    "    true_positive_rate = true_positive / total_faces if total_faces > 0 else -1\n",
    "    false_negative_rate = false_negative / total_faces if total_faces > 0 else -1\n",
    "    accuracy = (true_positive + true_negative) / total_faces if total_faces > 0 else -1\n",
    "\n",
    "    print(f\"True Positive: {true_positive}\")\n",
    "    print(f\"True Negative: {true_negative}\")\n",
    "    print(f\"False Positive: {false_positive}\")\n",
    "    print(f\"False Negative: {false_negative}\")\n",
    "\n",
    "    return error_rate, precision, false_discovery_rate, true_positive_rate, false_negative_rate, accuracy\n",
    "\n",
    "# Replace 'train_images_folder' and 'test_images_folder' with your directories\n",
    "train_images_folder = 'dataset2'\n",
    "test_images_folder = 'testDataset2'\n",
    "\n",
    "# Train the recognizer initially\n",
    "train_recognizer(train_images_folder)\n",
    "\n",
    "# Update the recognizer with additional data\n",
    "#for i in range(5):\n",
    "#    update_recognizer('dataset')\n",
    "\n",
    "# Calculate and print metrics\n",
    "error_rate, precision, false_discovery_rate, true_positive_rate, false_negative_rate, accuracy = calculate_metrics(test_images_folder)\n",
    "print(f\"Accuracy: {accuracy:.4f}\")\n",
    "print(f\"Error Rate: {error_rate:.4f}\")\n",
    "print(f\"Precision: {precision:.4f}\")\n",
    "print(f\"False Discovery Rate: {false_discovery_rate:.4f}\")\n",
    "print(f\"True Positive Rate: {true_positive_rate:.4f}\")\n",
    "print(f\"False Negative Rate: {false_negative_rate:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "True Positive: 28\n",
    "True Negative: 46\n",
    "False Positive: 106\n",
    "False Negative: 0\n",
    "Accuracy: 0.4111\n",
    "Error Rate: 0.5889\n",
    "Precision: 0.2090\n",
    "False Discovery Rate: 0.7910\n",
    "True Positive Rate: 0.1556\n",
    "False Negative Rate: 0.0000"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
